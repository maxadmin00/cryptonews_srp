{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91443e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c9f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from datetime import timedelta, datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345235c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://ria.ru/economy')\n",
    "data = []\n",
    "last_i = -1\n",
    "\n",
    "while True:\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    containers = soup.find_all(\"div\", attrs={\"class\": \"list-item\", \"data-type\": \"article\"})\n",
    "\n",
    "    for i, container in enumerate(containers):\n",
    "\n",
    "        if i < last_i:\n",
    "            continue\n",
    "        \n",
    "        header = container.find('a', attrs= {'class': re.compile('^list-item__title\\D*$')})\n",
    "        header_text = header.text\n",
    "        href = header['href']\n",
    "\n",
    "        # open the page\n",
    "        page = requests.get(href)\n",
    "        soup_inner = BeautifulSoup(page.text, 'html.parser')\n",
    "        dttime_el = soup_inner.find('div', attrs={'class': 'article__info-date'}).find('a')\n",
    "        dttime = dttime_el.text if dttime_el is not None else \"None\"\n",
    "        #author = \"NOT FOUND\"\n",
    "        brief_el = soup_inner.find('h1', attrs={'class': 'article__second-title'})\n",
    "        brief = \"None\" if brief_el is None else brief_el.text\n",
    "        tags_element = soup_inner.find('div', attrs={'class': 'article__tags'}).find_all('a')\n",
    "        tags = \",\".join([el.text for el in tags_element])\n",
    "\n",
    "\n",
    "        #//*[@id=\"content\"]/div/div[1]/div/div[3]\n",
    "\n",
    "        print(i, header_text, dttime, href, brief, tags)\n",
    "        data.append((header_text, dttime, href, brief, tags)) \n",
    "\n",
    "        last_i = i\n",
    "\n",
    "        #data.append((header, timedata, ref))\n",
    "        #print(f\"Found header: {header}, date: {timedata}, ref: {ref}\")\n",
    "\n",
    "    #//*[@id=\"content\"]/div/div[1]/div/div[3]\n",
    "    bottom = driver.find_element(By.XPATH, '//*[@id=\"content\"]/div/div[1]/div/div[3]')\n",
    "    location = bottom.location\n",
    "    size = bottom.size\n",
    "    action = ActionChains(driver) \n",
    "    action.move_to_element(bottom).perform()\n",
    "    driver.execute_script(\"arguments[0].click();\", bottom)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb2923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = ['header', 'date', 'link', 'brief', 'tags'])\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f074950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/ria_temp.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
